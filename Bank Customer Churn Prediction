
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
from google.colab import files

# Upload the dataset
uploaded = files.upload()



# Load the dataset into a DataFrame
data = pd.read_csv(io.BytesIO(uploaded['Bank Customer Churn Prediction.csv']))
print(data)

# Excluded non-numeric columns
numeric_columns = ['credit_score', 'age', 'tenure', 'balance', 'products_number', 'credit_card', 'active_member', 'estimated_salary']

# Ensure the columns exist in the DataFrame
missing_columns = [col for col in numeric_columns if col not in data.columns]
if missing_columns:
    print(f"Missing columns: {missing_columns}")
else:
    # Select the numeric columns
    X = data[numeric_columns]

    # Splitting data in target label
    y = data['churn']

    # Splitting data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Feature scaling
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)

    # Building and training the model (Random Forest)
    model = RandomForestClassifier()
    model.fit(X_train, y_train)

    # Predicting
    y_pred = model.predict(X_test)

    # Evaluating the model
    report = classification_report(y_test, y_pred)
    conf_matrix = confusion_matrix(y_test, y_pred)
    print("Classification Report:\n", report)
    print("Confusion Matrix:\n", conf_matrix)
